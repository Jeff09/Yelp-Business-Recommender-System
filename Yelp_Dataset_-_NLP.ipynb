{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Challenge - NLP\n",
    "\n",
    "BitTiger DS501\n",
    "\n",
    "Jun 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:09.788614Z",
     "start_time": "2018-01-02T22:00:03.280854Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:14.279942Z",
     "start_time": "2018-01-02T22:00:09.790503Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/last_3_years_restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:14.302505Z",
     "start_time": "2018-01-02T22:00:14.281448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDMCrFlGIFUN6L-FEFgzWg</td>\n",
       "      <td>El Pollo Loco</td>\n",
       "      <td>['Restaurants', 'American (Traditional)', 'Mex...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>0</td>\n",
       "      <td>4gH-5f0ewrH2Vvl0UYtQQA</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm at training for work and went for a quick ...</td>\n",
       "      <td>0</td>\n",
       "      <td>GLGz9sSNHIbguwv90XStYA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDMCrFlGIFUN6L-FEFgzWg</td>\n",
       "      <td>El Pollo Loco</td>\n",
       "      <td>['Restaurants', 'American (Traditional)', 'Mex...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>1</td>\n",
       "      <td>qlnMpBo8_GWhlJE6zR51qA</td>\n",
       "      <td>3</td>\n",
       "      <td>Given this location is close to my work I find...</td>\n",
       "      <td>2</td>\n",
       "      <td>YxqLJwDgcL4OoDB1hN-Ikg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDMCrFlGIFUN6L-FEFgzWg</td>\n",
       "      <td>El Pollo Loco</td>\n",
       "      <td>['Restaurants', 'American (Traditional)', 'Mex...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-15</td>\n",
       "      <td>0</td>\n",
       "      <td>woYGBjLlsrezUvBKiBwwhg</td>\n",
       "      <td>1</td>\n",
       "      <td>Never again will I return.  The culture of thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>i1zH7hGJs_accdfjEzrwUQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDMCrFlGIFUN6L-FEFgzWg</td>\n",
       "      <td>El Pollo Loco</td>\n",
       "      <td>['Restaurants', 'American (Traditional)', 'Mex...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-15</td>\n",
       "      <td>0</td>\n",
       "      <td>_u6u4NB9XTNPgDOqJUbF7Q</td>\n",
       "      <td>5</td>\n",
       "      <td>this one is one of my favorite locations . Foo...</td>\n",
       "      <td>0</td>\n",
       "      <td>5TRDoYHqVvC81mq_p76HlQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDMCrFlGIFUN6L-FEFgzWg</td>\n",
       "      <td>El Pollo Loco</td>\n",
       "      <td>['Restaurants', 'American (Traditional)', 'Mex...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>0</td>\n",
       "      <td>ilj0ZswUKjNMjw2kz7cgTg</td>\n",
       "      <td>4</td>\n",
       "      <td>A great mix between an authentic Mexican taco ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Pg-sMoiilKCVPs41vf5V_Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id           name  \\\n",
       "0  LDMCrFlGIFUN6L-FEFgzWg  El Pollo Loco   \n",
       "1  LDMCrFlGIFUN6L-FEFgzWg  El Pollo Loco   \n",
       "2  LDMCrFlGIFUN6L-FEFgzWg  El Pollo Loco   \n",
       "3  LDMCrFlGIFUN6L-FEFgzWg  El Pollo Loco   \n",
       "4  LDMCrFlGIFUN6L-FEFgzWg  El Pollo Loco   \n",
       "\n",
       "                                          categories  avg_stars  cool  \\\n",
       "0  ['Restaurants', 'American (Traditional)', 'Mex...        3.0     0   \n",
       "1  ['Restaurants', 'American (Traditional)', 'Mex...        3.0     2   \n",
       "2  ['Restaurants', 'American (Traditional)', 'Mex...        3.0     0   \n",
       "3  ['Restaurants', 'American (Traditional)', 'Mex...        3.0     0   \n",
       "4  ['Restaurants', 'American (Traditional)', 'Mex...        3.0     0   \n",
       "\n",
       "         date  funny               review_id  stars  \\\n",
       "0  2015-06-26      0  4gH-5f0ewrH2Vvl0UYtQQA      1   \n",
       "1  2015-06-18      1  qlnMpBo8_GWhlJE6zR51qA      3   \n",
       "2  2015-05-15      0  woYGBjLlsrezUvBKiBwwhg      1   \n",
       "3  2017-02-15      0  _u6u4NB9XTNPgDOqJUbF7Q      5   \n",
       "4  2015-06-16      0  ilj0ZswUKjNMjw2kz7cgTg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  I'm at training for work and went for a quick ...       0   \n",
       "1  Given this location is close to my work I find...       2   \n",
       "2  Never again will I return.  The culture of thi...       0   \n",
       "3  this one is one of my favorite locations . Foo...       0   \n",
       "4  A great mix between an authentic Mexican taco ...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  GLGz9sSNHIbguwv90XStYA  \n",
       "1  YxqLJwDgcL4OoDB1hN-Ikg  \n",
       "2  i1zH7hGJs_accdfjEzrwUQ  \n",
       "3  5TRDoYHqVvC81mq_p76HlQ  \n",
       "4  Pg-sMoiilKCVPs41vf5V_Q  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your feature variables, here is the text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:14.393599Z",
     "start_time": "2018-01-02T22:00:14.304534Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents\"\n",
    "documents = df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:14.488089Z",
     "start_time": "2018-01-02T22:00:14.394924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(437524,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect your documents, e.g. check the size, take a peek at elements of the numpy array\n",
    "documents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your target variable (any categorical variable that may be meaningful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example, I am interested in perfect (5 stars) and imperfect (1-4 stars) rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:14.562472Z",
     "start_time": "2018-01-02T22:00:14.490072Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a column and take the values, save to a variable named \"target\"\n",
    "df['favorable'] = df['stars']>4\n",
    "target = df['favorable'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You may want to look at the statistic of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:14.709539Z",
     "start_time": "2018-01-02T22:00:14.563908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45755661403717279"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To be implemented\n",
    "target.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create training dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:18.626609Z",
     "start_time": "2018-01-02T22:00:14.975053Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:23.189731Z",
     "start_time": "2018-01-02T22:00:23.119954Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Documents is your X, target is your y\n",
    "# Now split the data to training set and test set\n",
    "documents_train, documents_test, target_train, target_test = train_test_split(documents, target, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:25.556325Z",
     "start_time": "2018-01-02T22:00:25.552304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87504,), (350020,), (87504,), (350020,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split to documents_train, documents_test, target_train, target_test\n",
    "documents_train.shape, documents_test.shape, target_train.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get NLP representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:32.845763Z",
     "start_time": "2018-01-02T22:00:32.623965Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:33.043407Z",
     "start_time": "2018-01-02T22:00:33.040399Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:39.634780Z",
     "start_time": "2018-01-02T22:00:34.342994Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model with your training data\n",
    "vector_train = vectorizer.fit_transform(documents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:01:13.783134Z",
     "start_time": "2018-01-02T22:01:13.178024Z"
    }
   },
   "outputs": [],
   "source": [
    "vector_train = vector_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:00:42.020983Z",
     "start_time": "2018-01-02T22:00:42.007448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '00pm',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10am',\n",
       " '10pm',\n",
       " '11',\n",
       " '110',\n",
       " '11am',\n",
       " '11pm',\n",
       " '12',\n",
       " '120',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '150',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '1am',\n",
       " '1pm',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '21',\n",
       " '215',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '250',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2am',\n",
       " '2nd',\n",
       " '2pm',\n",
       " '30',\n",
       " '300',\n",
       " '30am',\n",
       " '30pm',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '3am',\n",
       " '3pm',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '42',\n",
       " '45',\n",
       " '48',\n",
       " '49',\n",
       " '4pm',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '55',\n",
       " '59',\n",
       " '5pm',\n",
       " '5th',\n",
       " '60',\n",
       " '65',\n",
       " '6pm',\n",
       " '70',\n",
       " '75',\n",
       " '7pm',\n",
       " '80',\n",
       " '85',\n",
       " '8am',\n",
       " '8pm',\n",
       " '90',\n",
       " '95',\n",
       " '99',\n",
       " '9am',\n",
       " '9pm',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'abundance',\n",
       " 'ac',\n",
       " 'acai',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodating',\n",
       " 'accompanied',\n",
       " 'accompanying',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accurate',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'action',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adjacent',\n",
       " 'adjust',\n",
       " 'admit',\n",
       " 'admittedly',\n",
       " 'adobada',\n",
       " 'adobo',\n",
       " 'adorable',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adventurous',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'af',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afraid',\n",
       " 'afternoon',\n",
       " 'aftertaste',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'ages',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'ahead',\n",
       " 'ahi',\n",
       " 'ain',\n",
       " 'aioli',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'airy',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alas',\n",
       " 'alaskan',\n",
       " 'albacore',\n",
       " 'albeit',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'ale',\n",
       " 'alex',\n",
       " 'alfredo',\n",
       " 'alike',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'alley',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'almond',\n",
       " 'almonds',\n",
       " 'aloha',\n",
       " 'alongside',\n",
       " 'alot',\n",
       " 'alright',\n",
       " 'alternative',\n",
       " 'altogether',\n",
       " 'amanda',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanized',\n",
       " 'ami',\n",
       " 'amounts',\n",
       " 'ample',\n",
       " 'amuse',\n",
       " 'andy',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angry',\n",
       " 'angus',\n",
       " 'animal',\n",
       " 'anniversary',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anthony',\n",
       " 'anticipated',\n",
       " 'antipasto',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anytime',\n",
       " 'anyways',\n",
       " 'apart',\n",
       " 'apologetic',\n",
       " 'apologies',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appetite',\n",
       " 'appetizer',\n",
       " 'appetizers',\n",
       " 'appetizing',\n",
       " 'apple',\n",
       " 'applebee',\n",
       " 'apples',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'april',\n",
       " 'arcade',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arepa',\n",
       " 'arepas',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'aria',\n",
       " 'arizona',\n",
       " 'arm',\n",
       " 'aroma',\n",
       " 'array',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'art',\n",
       " 'artichoke',\n",
       " 'artwork',\n",
       " 'arugula',\n",
       " 'asada',\n",
       " 'asap',\n",
       " 'ashamed',\n",
       " 'ashley',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asparagus',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'assist',\n",
       " 'assistant',\n",
       " 'assorted',\n",
       " 'assortment',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assured',\n",
       " 'ate',\n",
       " 'atleast',\n",
       " 'atmosphere',\n",
       " 'atop',\n",
       " 'atrocious',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attend',\n",
       " 'attendant',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attentive',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attractive',\n",
       " 'au',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'authentic',\n",
       " 'authenticity',\n",
       " 'automatically',\n",
       " 'available',\n",
       " 'average',\n",
       " 'avocado',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'ayce',\n",
       " 'baby',\n",
       " 'babystacks',\n",
       " 'bacchanal',\n",
       " 'bachelor',\n",
       " 'bachelorette',\n",
       " 'bachi',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'bagel',\n",
       " 'bagels',\n",
       " 'bags',\n",
       " 'baguette',\n",
       " 'baja',\n",
       " 'bake',\n",
       " 'baked',\n",
       " 'bakery',\n",
       " 'baklava',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balcony',\n",
       " 'ball',\n",
       " 'balls',\n",
       " 'bally',\n",
       " 'balsamic',\n",
       " 'bamboo',\n",
       " 'banana',\n",
       " 'bananas',\n",
       " 'banchan',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'banh',\n",
       " 'bank',\n",
       " 'bao',\n",
       " 'bar',\n",
       " 'barbacoa',\n",
       " 'barbecue',\n",
       " 'bare',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'barley',\n",
       " 'barrel',\n",
       " 'bars',\n",
       " 'bartender',\n",
       " 'bartenders',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basics',\n",
       " 'basil',\n",
       " 'basis',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'bass',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'bathroom',\n",
       " 'bathrooms',\n",
       " 'batter',\n",
       " 'battered',\n",
       " 'bay',\n",
       " 'bazaar',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'beach',\n",
       " 'bean',\n",
       " 'beans',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'bed',\n",
       " 'beds',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'beet',\n",
       " 'beets',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behavior',\n",
       " 'beignets',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'bellagio',\n",
       " 'belly',\n",
       " 'belt',\n",
       " 'benedict',\n",
       " 'benefit',\n",
       " 'benny',\n",
       " 'bento',\n",
       " 'berries',\n",
       " 'berry',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'beverage',\n",
       " 'beverages',\n",
       " 'beware',\n",
       " 'bf',\n",
       " 'biased',\n",
       " 'bibimbap',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'biggie',\n",
       " 'bills',\n",
       " 'billy',\n",
       " 'bird',\n",
       " 'birthday',\n",
       " 'birthdays',\n",
       " 'biryani',\n",
       " 'biscuit',\n",
       " 'biscuits',\n",
       " 'bison',\n",
       " 'bisque',\n",
       " 'bistro',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bites',\n",
       " 'bits',\n",
       " 'bitter',\n",
       " 'black',\n",
       " 'blackened',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'bland',\n",
       " 'blast',\n",
       " 'blaze',\n",
       " 'blend',\n",
       " 'blended',\n",
       " 'bleu',\n",
       " 'blew',\n",
       " 'block',\n",
       " 'blocks',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blows',\n",
       " 'blt',\n",
       " 'blue',\n",
       " 'blueberries',\n",
       " 'blueberry',\n",
       " 'blvd',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'boba',\n",
       " 'bobby',\n",
       " 'body',\n",
       " 'bogo',\n",
       " 'boiled',\n",
       " 'boiling',\n",
       " 'bold',\n",
       " 'bolognese',\n",
       " 'bomb',\n",
       " 'bombs',\n",
       " 'bone',\n",
       " 'boneless',\n",
       " 'bones',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'bookmarked',\n",
       " 'books',\n",
       " 'boot',\n",
       " 'booth',\n",
       " 'booths',\n",
       " 'booze',\n",
       " 'border',\n",
       " 'borderline',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bothering',\n",
       " 'bottle',\n",
       " 'bottled',\n",
       " 'bottles',\n",
       " 'bottomless',\n",
       " 'bouchon',\n",
       " 'bought',\n",
       " 'boulevard',\n",
       " 'bourbon',\n",
       " 'bowl',\n",
       " 'bowling',\n",
       " 'bowls',\n",
       " 'box',\n",
       " 'boxed',\n",
       " 'boxes',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boyfriends',\n",
       " 'boys',\n",
       " 'brag',\n",
       " 'braised',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brandon',\n",
       " 'branzino',\n",
       " 'bravo',\n",
       " 'brazil',\n",
       " 'brazilian',\n",
       " 'bread',\n",
       " 'breaded',\n",
       " 'breading',\n",
       " 'breads',\n",
       " 'breadsticks',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breakfasts',\n",
       " 'breaking',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breeze',\n",
       " 'brew',\n",
       " 'brewed',\n",
       " 'brewery',\n",
       " 'brews',\n",
       " 'brian',\n",
       " 'brick',\n",
       " 'brie',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'brio',\n",
       " 'brioche',\n",
       " 'brisket',\n",
       " 'british',\n",
       " 'broccoli',\n",
       " 'broccolini',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brooklyn',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'broths',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brownie',\n",
       " 'browns',\n",
       " 'brulee',\n",
       " 'brunch',\n",
       " 'bruschetta',\n",
       " 'brussel',\n",
       " 'brussels',\n",
       " 'brûlée',\n",
       " 'bs',\n",
       " 'btw',\n",
       " 'bubble',\n",
       " 'buck',\n",
       " 'bucket',\n",
       " 'bucks',\n",
       " 'bud',\n",
       " 'buddies',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buds',\n",
       " 'buffalo',\n",
       " 'buffet',\n",
       " 'buffets',\n",
       " 'buffett',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bulgogi',\n",
       " 'bull',\n",
       " 'bummed',\n",
       " 'bummer',\n",
       " 'bun',\n",
       " 'bunch',\n",
       " 'buns',\n",
       " 'burger',\n",
       " 'burgers',\n",
       " 'burgr',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'burrata',\n",
       " 'burrito',\n",
       " 'burritos',\n",
       " 'bursting',\n",
       " 'bus',\n",
       " 'busboy',\n",
       " 'busier',\n",
       " 'business',\n",
       " 'businesses',\n",
       " 'busser',\n",
       " 'busy',\n",
       " 'butcher',\n",
       " 'butt',\n",
       " 'butter',\n",
       " 'buttered',\n",
       " 'buttermilk',\n",
       " 'buttery',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'buzz',\n",
       " 'buzzer',\n",
       " 'bye',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cabbage',\n",
       " 'caesar',\n",
       " 'caesars',\n",
       " 'cafe',\n",
       " 'cafeteria',\n",
       " 'café',\n",
       " 'cajun',\n",
       " 'cake',\n",
       " 'cakes',\n",
       " 'cal',\n",
       " 'calamari',\n",
       " 'cali',\n",
       " 'caliber',\n",
       " 'california',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'calm',\n",
       " 'calories',\n",
       " 'calzone',\n",
       " 'came',\n",
       " 'canal',\n",
       " 'cancel',\n",
       " 'cancelled',\n",
       " 'candied',\n",
       " 'candle',\n",
       " 'candy',\n",
       " 'cane',\n",
       " 'canes',\n",
       " 'canned',\n",
       " 'cannoli',\n",
       " 'cantina',\n",
       " 'cantonese',\n",
       " 'cap',\n",
       " 'capacity',\n",
       " 'capers',\n",
       " 'capital',\n",
       " 'cappuccino',\n",
       " 'caprese',\n",
       " 'car',\n",
       " 'caramel',\n",
       " 'caramelized',\n",
       " 'carb',\n",
       " 'carbonara',\n",
       " 'carbs',\n",
       " 'card',\n",
       " 'cardboard',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'cared',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'cares',\n",
       " 'caring',\n",
       " 'carlo',\n",
       " 'carlos',\n",
       " 'carmine',\n",
       " 'carne',\n",
       " 'carnitas',\n",
       " 'carpaccio',\n",
       " 'carpet',\n",
       " 'carried',\n",
       " 'carrot',\n",
       " 'carrots',\n",
       " 'carry',\n",
       " 'cars',\n",
       " 'carson',\n",
       " 'cart',\n",
       " 'carte',\n",
       " 'carts',\n",
       " 'carved',\n",
       " 'carving',\n",
       " 'casa',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'cash',\n",
       " 'cashew',\n",
       " 'cashier',\n",
       " 'cashiers',\n",
       " 'casino',\n",
       " 'casinos',\n",
       " 'cast',\n",
       " 'castle',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catching',\n",
       " 'category',\n",
       " 'cater',\n",
       " 'catered',\n",
       " 'catering',\n",
       " 'catfish',\n",
       " 'caught',\n",
       " 'cauliflower',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'caviar',\n",
       " 'ceasar',\n",
       " 'ceiling',\n",
       " 'ceilings',\n",
       " 'celebrate',\n",
       " 'celebrated',\n",
       " 'celebrating',\n",
       " 'celebration',\n",
       " 'celebrity',\n",
       " 'celery',\n",
       " 'cell',\n",
       " 'cent',\n",
       " 'centennial',\n",
       " 'center',\n",
       " 'central',\n",
       " 'cents',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'cesar',\n",
       " 'ceviche',\n",
       " 'cha',\n",
       " 'chai',\n",
       " 'chain',\n",
       " 'chains',\n",
       " 'chair',\n",
       " 'chairs',\n",
       " 'challenge',\n",
       " 'champagne',\n",
       " 'chance',\n",
       " 'chances',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chaos',\n",
       " 'char',\n",
       " 'character',\n",
       " 'charcuterie',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charges',\n",
       " 'charging',\n",
       " 'charleston',\n",
       " 'charlie',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'charred',\n",
       " 'charts',\n",
       " 'chase',\n",
       " 'chashu',\n",
       " 'chat',\n",
       " 'chatted',\n",
       " 'chatting',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'cheapest',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'checks',\n",
       " 'cheddar',\n",
       " 'cheek',\n",
       " 'cheerful',\n",
       " 'cheers',\n",
       " 'cheese',\n",
       " 'cheeseburger',\n",
       " 'cheesecake',\n",
       " 'cheeses',\n",
       " 'cheesesteak',\n",
       " 'cheesy',\n",
       " 'chef',\n",
       " 'chefs',\n",
       " 'cherry',\n",
       " 'chew',\n",
       " 'chewing',\n",
       " 'chewy',\n",
       " 'chic',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chilaquiles',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'chile',\n",
       " 'chilean',\n",
       " 'chili',\n",
       " 'chill',\n",
       " 'chilled',\n",
       " 'chilli',\n",
       " 'chilly',\n",
       " 'chimichanga',\n",
       " 'chimichurri',\n",
       " 'china',\n",
       " 'chinatown',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'chipotle',\n",
       " 'chips',\n",
       " 'chives',\n",
       " 'chix',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'choosing',\n",
       " 'chop',\n",
       " 'chopped',\n",
       " 'chops',\n",
       " 'chopsticks',\n",
       " 'chorizo',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chow',\n",
       " 'chowder',\n",
       " 'choy',\n",
       " 'chris',\n",
       " 'christina',\n",
       " 'christmas',\n",
       " 'chuck',\n",
       " 'chunk',\n",
       " 'chunks',\n",
       " 'chunky',\n",
       " 'church',\n",
       " 'churro',\n",
       " 'churros',\n",
       " 'chutney',\n",
       " 'cider',\n",
       " 'cigarette',\n",
       " 'cilantro',\n",
       " 'cinnamon',\n",
       " 'circle',\n",
       " 'circus',\n",
       " 'cirque',\n",
       " 'citrus',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'claimed',\n",
       " 'clam',\n",
       " 'clams',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classics',\n",
       " 'classy',\n",
       " 'claws',\n",
       " 'clean',\n",
       " 'cleaned',\n",
       " 'cleaner',\n",
       " 'cleaning',\n",
       " 'cleanliness',\n",
       " 'clear',\n",
       " 'cleared',\n",
       " 'clearing',\n",
       " 'clearly',\n",
       " 'clientele',\n",
       " 'clients',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'closes',\n",
       " 'closest',\n",
       " 'closing',\n",
       " 'clothes',\n",
       " 'club',\n",
       " 'clubbing',\n",
       " 'clubs',\n",
       " 'clue',\n",
       " 'clueless',\n",
       " 'coast',\n",
       " 'coated',\n",
       " 'coating',\n",
       " 'cob',\n",
       " 'cobb',\n",
       " 'cobbler',\n",
       " 'cocktail',\n",
       " 'cocktails',\n",
       " 'coconut',\n",
       " 'cod',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'coffees',\n",
       " 'coke',\n",
       " 'cold',\n",
       " 'cole',\n",
       " 'coleslaw',\n",
       " 'collard',\n",
       " 'colleagues',\n",
       " 'college',\n",
       " 'color',\n",
       " 'colored',\n",
       " 'colorful',\n",
       " 'colors',\n",
       " 'com',\n",
       " 'coma',\n",
       " 'combination',\n",
       " 'combinations',\n",
       " 'combined',\n",
       " 'combo',\n",
       " 'combos',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comforting',\n",
       " 'comfy',\n",
       " 'comida',\n",
       " 'coming',\n",
       " 'comment',\n",
       " 'commented',\n",
       " 'comments',\n",
       " 'commercial',\n",
       " 'common',\n",
       " 'communication',\n",
       " 'community',\n",
       " 'comp',\n",
       " 'companion',\n",
       " 'companions',\n",
       " 'company',\n",
       " 'comparable',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'compares',\n",
       " 'comparing',\n",
       " 'comparison',\n",
       " 'comped',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocab of your tfidf\n",
    "words = vectorizer.get_feature_names()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:01:10.751192Z",
     "start_time": "2018-01-02T22:00:49.984465Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the trained model to transform your test data\n",
    "vector_test = vectorizer.transform(documents_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar review search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:01:10.761194Z",
     "start_time": "2018-01-02T22:01:10.752670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We will need these helper methods pretty soon\n",
    "\n",
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"cat\", \"pig\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[::-1][:n]]  # np.argsort by default sorts values in ascending order\n",
    "\n",
    "def get_bottom_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the lowest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"mouse\", \"rabbit\"]\n",
    "    '''\n",
    "    #pass  # To be implemented\n",
    "    return [labels[i] for i in np.argsort(lst)[:n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:01:19.786829Z",
     "start_time": "2018-01-02T22:01:19.783821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's use cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:01:21.538921Z",
     "start_time": "2018-01-02T22:01:21.535913Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw an arbitrary review from test (unseen in training) documents\n",
    "sample = np.random.choice(len(documents_test))\n",
    "sample_view = documents_test[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:01:22.115034Z",
     "start_time": "2018-01-02T22:01:22.111046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Best Ramen ever!!! We got the Brussels Sprouts tempura to start and the Creamy Spicy Vegan Ramen and Vegetable Ramen and it was SO delicious!!! Can't wait to come back!!\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:01:26.667674Z",
     "start_time": "2018-01-02T22:01:26.664188Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the drawn review(s) to vector(s)\n",
    "sample_vector = vectorizer.transform([sample_view]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:01:38.413244Z",
     "start_time": "2018-01-02T22:01:28.208478Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the similarity score(s) between vector(s) and training vectors\n",
    "sim_scores = cosine_similarity(vector_train, sample_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:01:38.517522Z",
     "start_time": "2018-01-02T22:01:38.436807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87504, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:01:40.941972Z",
     "start_time": "2018-01-02T22:01:40.880814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[ 'I went for happy hour and it was amazing! Brandon and Robert were amazing bartenders, super friendly and attentive. The Mai tai was delicious! The appetizers like the crab balls were great and filling! Def would come back again!']\n",
      "\n",
      "1\n",
      "[ 'I went for happy hour and it was amazing! Brandon and Robert were amazing bartenders, super friendly and attentive. The Mai tai was delicious! The appetizers like the crab balls were great and filling! Def would come back again!']\n",
      "\n",
      "2\n",
      "[ 'I went for happy hour and it was amazing! Brandon and Robert were amazing bartenders, super friendly and attentive. The Mai tai was delicious! The appetizers like the crab balls were great and filling! Def would come back again!']\n",
      "\n",
      "3\n",
      "[ 'I went for happy hour and it was amazing! Brandon and Robert were amazing bartenders, super friendly and attentive. The Mai tai was delicious! The appetizers like the crab balls were great and filling! Def would come back again!']\n",
      "\n",
      "4\n",
      "[ 'I went for happy hour and it was amazing! Brandon and Robert were amazing bartenders, super friendly and attentive. The Mai tai was delicious! The appetizers like the crab balls were great and filling! Def would come back again!']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's find top 5 similar reviews\n",
    "n = 5\n",
    "top5 = get_top_values(sim_scores, n, documents_train)\n",
    "for i in range(n):\n",
    "    print(i)\n",
    "    print('{}'.format(top5[i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Our search query:'\n",
    "print  # To be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Most %s similar reviews:' % n\n",
    "print  # To be added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Does the result make sense to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (insert your comments here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying positive/negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:04:06.768035Z",
     "start_time": "2018-01-02T22:04:02.903730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Naive-Bayes Classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_nb = MultinomialNB()\n",
    "\n",
    "model_nb.fit(vector_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:04:31.798515Z",
     "start_time": "2018-01-02T22:04:30.327448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80776878771256166"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_nb.score(vector_train, target_train) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:04:44.953374Z",
     "start_time": "2018-01-02T22:04:44.624088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80208273812924979"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_nb.score(vector_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:05:04.318666Z",
     "start_time": "2018-01-02T22:04:59.463298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Logistic Regression Classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lrc = LogisticRegression()\n",
    "model_lrc.fit(vector_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:05:15.679036Z",
     "start_time": "2018-01-02T22:05:14.839775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84123011519473401"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_lrc.score(vector_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:05:26.778259Z",
     "start_time": "2018-01-02T22:05:26.687636Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82505856808182387"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_lrc.score(vector_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What are the key features(words) that make the positive prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:06:09.789353Z",
     "start_time": "2018-01-02T22:06:09.783838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazing',\n",
       " 'best',\n",
       " 'perfect',\n",
       " 'highly',\n",
       " 'awesome',\n",
       " 'delicious',\n",
       " 'phenomenal',\n",
       " 'excellent',\n",
       " 'heaven',\n",
       " 'fantastic',\n",
       " 'thank',\n",
       " 'incredible',\n",
       " 'perfection',\n",
       " 'perfectly',\n",
       " 'great',\n",
       " 'die',\n",
       " 'favorite',\n",
       " 'gem',\n",
       " 'outstanding',\n",
       " 'fabulous']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find it out by ranking\n",
    "n = 20\n",
    "get_top_values(model_lrc.coef_[0], n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (insert your comments here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What are the key features(words) that make the negative prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:06:24.341848Z",
     "start_time": "2018-01-02T22:06:24.336835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'ok',\n",
       " 'horrible',\n",
       " 'slow',\n",
       " 'rude',\n",
       " 'bland',\n",
       " 'terrible',\n",
       " 'mediocre',\n",
       " 'disappointing',\n",
       " 'average',\n",
       " 'okay',\n",
       " 'poor',\n",
       " 'dry',\n",
       " 'unfortunately',\n",
       " 'decent',\n",
       " 'lacking',\n",
       " 'overpriced',\n",
       " 'wasn',\n",
       " 'bad',\n",
       " 'worse']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find it out by ranking\n",
    "n = 20\n",
    "get_bottom_values(model_lrc.coef_[0], n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (insert your comments here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:06:59.388006Z",
     "start_time": "2018-01-02T22:06:44.263853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rfc = RandomForestClassifier(max_depth = None,\n",
    "                                   n_estimators = 5,\n",
    "                                   min_samples_leaf = 10)\n",
    "model_rfc.fit(vector_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:07:07.955733Z",
     "start_time": "2018-01-02T22:07:06.456745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81291140976412501"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_rfc.score(vector_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:07:08.838647Z",
     "start_time": "2018-01-02T22:07:08.040507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76867607565281981"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_rfc.score(vector_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What do you see from the training score and the test score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: (insert your comments here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Can you tell what features (words) are important by inspecting the RFC model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:07:28.196815Z",
     "start_time": "2018-01-02T22:07:28.191779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best',\n",
       " 'great',\n",
       " 'bad',\n",
       " 'amazing',\n",
       " 'delicious',\n",
       " 'love',\n",
       " 'ok',\n",
       " 'definitely',\n",
       " 'worst',\n",
       " 'okay',\n",
       " 'terrible',\n",
       " 'awesome',\n",
       " 'horrible',\n",
       " 'wasn',\n",
       " 'decent',\n",
       " 'excellent',\n",
       " 'vegas',\n",
       " 'said',\n",
       " 'favorite',\n",
       " 'place']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "get_top_values(model_rfc.feature_importances_, n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit #1: Use cross validation to evaluate your classifiers\n",
    "\n",
    "[sklearn cross validation](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:08:24.808994Z",
     "start_time": "2018-01-02T22:08:09.024385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82149591,  0.8213245 ,  0.82006742,  0.82309582,  0.82285714])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To be implemented\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(model_lrc,\n",
    "                            vector_train,\n",
    "                            target_train,\n",
    "                            cv = 5,\n",
    "                            scoring=\"accuracy\")\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit #2: Use grid search to find best predictable classifier\n",
    "\n",
    "\n",
    "[sklearn grid search tutorial (with cross validation)](http://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n",
    "\n",
    "[sklearn grid search documentation (with cross validation)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T22:09:11.906941Z",
     "start_time": "2018-01-02T22:09:11.313021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "\n",
      "{'C': 100, 'penalty': 'l2'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "\n",
      "0.548 (+/-0.005) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.722 (+/-0.078) for {'C': 100, 'penalty': 'l1'}\n",
      "0.562 (+/-0.024) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.730 (+/-0.053) for {'C': 100, 'penalty': 'l2'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.79      0.77    190008\n",
      "       True       0.73      0.68      0.70    160012\n",
      "\n",
      "avg / total       0.74      0.74      0.74    350020\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To be implemented\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "param_grid = [{'penalty':['l1'], 'C':[0.1, 100]},\n",
    "              {'penalty':['l2'], 'C':[0.1, 100]}]\n",
    "\n",
    "scores = ['accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score + \"\\n\\n\")\n",
    "    clf = GridSearchCV(LogisticRegression(),\n",
    "                       param_grid,\n",
    "                       cv=5,\n",
    "                       scoring=score)\n",
    "    clf.fit(vector_train[:500,:], target_train[:500])\n",
    "    print(\"Best parameters set found on development set:\\n\\n\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"\\nGrid scores on development set:\\n\\n\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    \n",
    "    print(\"\\nDetailed classification report:\\n\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print(\"\\n\")\n",
    "    y_true, y_pred = target_test, clf.predict(vector_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
